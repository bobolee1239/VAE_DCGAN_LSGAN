{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNN_Architecture:\n",
    "    def __init__(self, numFilters, filterSize, strides, toPadding, \n",
    "                useReLU, numInputChannels, maxPoolingSize=None):\n",
    "        self.numFilters = numFilters\n",
    "        self.filterSize = filterSize\n",
    "        self.strides = strides\n",
    "        self.maxPoolingSize = maxPoolingSize\n",
    "        self.toPadding = toPadding\n",
    "        self.useReLU = useReLU\n",
    "        self.numInputChannels = numInputChannels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_weights(shape):\n",
    "    stdev = 0.1\n",
    "    w = tf.Variable(tf.random_uniform(shape=shape, minval = -stdev, maxval = stdev))\n",
    "    return w\n",
    "\n",
    "def new_biases(length):\n",
    "    stdev = 0.1\n",
    "    b = tf.Variable(tf.random_uniform(shape=[length], minval = -stdev, maxval = stdev))\n",
    "    return b\n",
    "\n",
    "def new_convLayer(inputLayer, cnnArchitecture, name = \"conv2d\", stdev = 0.01):\n",
    "    with tf.variable_scope(name):\n",
    "        paddingAlgorithm = 'SAME' if cnnArchitecture.toPadding else 'VALID'\n",
    "        filterSpec = list(cnnArchitecture.filterSize) + [cnnArchitecture.numInputChannels, \n",
    "                                                         cnnArchitecture.numFilters]\n",
    "        weights = tf.get_variable('w', filterSpec, \n",
    "                          initializer = tf.truncated_normal_initializer(stddev=stdev))\n",
    "        biases = tf.get_variable('bias', [cnnArchitecture.numFilters], \n",
    "                                  initializer = tf.constant_initializer(0.0))\n",
    "\n",
    "        convLayer = tf.nn.conv2d(input = inputLayer, \n",
    "                                 filter = weights, \n",
    "                                 strides = [1, cnnArchitecture.strides, \n",
    "                                            cnnArchitecture.strides, 1], \n",
    "                                 padding = paddingAlgorithm)\n",
    "        convLayer = convLayer + biases\n",
    "\n",
    "        if cnnArchitecture.maxPoolingSize:\n",
    "            steps = [1, cnnArchitecture.maxPoolingSize[0], \n",
    "                        cnnArchitecture.maxPoolingSize[1], 1]\n",
    "            convLayer = tf.nn.max_pool(value=convLayer, \n",
    "                                       ksize=steps, \n",
    "                                       strides = steps, \n",
    "                                       padding = paddingAlgorithm)\n",
    "        if cnnArchitecture.useReLU: \n",
    "            convLayer = tf.nn.relu(convLayer)\n",
    "\n",
    "        return convLayer, weights\n",
    "\n",
    "def new_dconvLayer(inputLayer, cnnArchitecture, outputShape, \n",
    "                   name = \"dconv2d\", stdev = 0.01):\n",
    "    with tf.variable_scope(name):\n",
    "        paddingAlgorithm = 'SAME' if cnnArchitecture.toPadding else 'VALID'\n",
    "        filterSpec = list(cnnArchitecture.filterSize) + [cnnArchitecture.numFilters, \n",
    "                                                         cnnArchitecture.numInputChannels]\n",
    "        weights = tf.get_variable('w', filterSpec, \n",
    "                          initializer = tf.truncated_normal_initializer(stddev=stdev))\n",
    "#         weights = tf.get_variable('w', filterSpec, \n",
    "#                           initializer = tf.random_uniform_initializer(-1.0, 1.0))\n",
    "        biases = tf.get_variable('bias', [outputShape[-1]], \n",
    "                                  initializer = tf.constant_initializer(0.0))\n",
    "#         biases = tf.get_variable('bias', [outputShape[-1]], \n",
    "#                                   initializer = tf.random_uniform_initializer(-1.0, 1.0))\n",
    "\n",
    "        convLayer = tf.nn.conv2d_transpose(inputLayer, \n",
    "                                           output_shape=outputShape,\n",
    "                                           filter = weights, \n",
    "                                           strides = [1, cnnArchitecture.strides, \n",
    "                                                        cnnArchitecture.strides, 1], \n",
    "                                           padding = paddingAlgorithm)\n",
    "        convLayer = convLayer + biases\n",
    "\n",
    "#         if cnnArchitecture.maxPoolingSize:\n",
    "#             steps = [1, cnnArchitecture.maxPoolingSize[0], \n",
    "#                         cnnArchitecture.maxPoolingSize[1], 1]\n",
    "#             convLayer = tf.nn.max_pool(value=convLayer, \n",
    "#                                        ksize=steps, \n",
    "#                                        strides = steps, \n",
    "#                                        padding = paddingAlgorithm)\n",
    "        if cnnArchitecture.useReLU: \n",
    "            convLayer = tf.nn.relu(convLayer)\n",
    "#             convLayer = tf.maximum(convLayer, 0.2*convLayer)\n",
    "\n",
    "        return convLayer\n",
    "\n",
    "def flattenLayer(layer):\n",
    "    \"\"\"\n",
    "    [height, width, numFilters]\n",
    "    \"\"\"\n",
    "    shape = layer.get_shape()\n",
    "    # shape = [#imgs, height, width, numFilters]\n",
    "    numAttrs = shape[1:].num_elements()\n",
    "    \n",
    "    layer_flat = tf.reshape(layer, shape=[-1, numAttrs])\n",
    "    return layer_flat, numAttrs\n",
    "\n",
    "def new_fcLayer(inputLayer, inputChannels, outputChannels, useReLU=True, \n",
    "                name=\"fc\", stdev=0.01):\n",
    "    with tf.variable_scope(name):\n",
    "        weights = tf.get_variable('w', shape=[inputChannels, outputChannels], \n",
    "                                initializer=tf.truncated_normal_initializer(stddev=stdev))\n",
    "#         weights = tf.get_variable('w', shape=[inputChannels, outputChannels], \n",
    "#                                 initializer=tf.random_uniform_initializer(-1.0, 1.0))\n",
    "        biases = tf.get_variable('bias', shape=[outputChannels], \n",
    "                                 initializer=tf.constant_initializer(0.0))\n",
    "#         biases = tf.get_variable('bias', shape=[outputChannels], \n",
    "#                                  initializer=tf.random_uniform_initializer(-1.0, 1.0))\n",
    "        layer = tf.matmul(inputLayer, weights) + biases\n",
    "        if useReLU:\n",
    "            layer = tf.nn.relu(layer)\n",
    "#             layer = tf.maximum(layer, 0.2*layer)\n",
    "        return layer\n",
    "    \n",
    "def bn(x, is_training, scope):\n",
    "    return tf.contrib.layers.batch_norm(x,\n",
    "                                        decay=0.9,\n",
    "                                        updates_collections=None,\n",
    "                                        epsilon=1e-5,\n",
    "                                        scale=True,\n",
    "                                        is_training=is_training,\n",
    "                                        scope=scope)\n",
    "\n",
    "def unpool(pool, kernel=(2, 2)):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # pool shape = (batch, height, width, channels)\n",
    "    img_size = pool.get_shape()[1:3]\n",
    "    out_size = [s.value * k for s, k in zip(img_size, kernel)]\n",
    "    \n",
    "#     unpool = tf.image.resize_images(pool, size = out_size, method=tf.image.ResizeMethod.BICUBIC)\n",
    "#     return unpool\n",
    "#     out = tf.concat_v2([x, tf.zeros_like(x)], 3)\n",
    "#     out = tf.concat_v2([out, tf.zeros_like(out)], 2)\n",
    "#     out_size = output_shape\n",
    "    return tf.image.resize_nearest_neighbor(pool, tf.stack(out_size))\n",
    "\n",
    "def lrelu(x, leak=0.2, name=\"lrelu\"):\n",
    "    return tf.maximum(x, leak*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    cnnArchitecture = CNN_Architecture(numFilters = 20, \n",
    "                                       filterSize = (3, 3), \n",
    "                                       strides = 2, \n",
    "                                       toPadding = False, \n",
    "                                       useReLU = True,\n",
    "                                       numInputChannels = 200,\n",
    "                                       maxPoolingSize=(2, 2))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [tensorflow-gpu]",
   "language": "python",
   "name": "Python [tensorflow-gpu]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
